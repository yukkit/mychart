# Default values for linkoopdb.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

image:
  repository: 192.168.1.79:5000/linkoopdb
  tag: v2.3.0-latest
  pullPolicy: Always
  imagePullSecrets:

#hostNetwork: false

shareDisk: /tmp/linkoopdb

hadoop:
  dependecy: false
  user: hdfs
  confPath:
    conf: /etc/hadoop/conf
#   hdp: /etc/hadoop/hdp

license:
  type: datapps
  host: license.datapps.com
  port: 7700

nfs:
  create: false
  mountPath: /fsshare
  storage: 100Gi
  path: /tmp/nfs
  node: node61
  reclaimPolicy: Retain
  label:
    key: pv
    value: pvc-001

#ldbDist:
#  - domain:
#    port:
#    node:
#    rootPath:

shuffleService:
  create: true
  localDir:
    disk1: /tmp/spark-local
  resources:
    limits: {}
    requests: {}

metastore:
  type: LINKOOPDB
  replicas: 3
  nodeAffinity:
    key: linkoopdb/metaserver
    value: true
  storage:
    nodeAffinity:
      key: linkoopdb/metastorage
      value: true
  config:
    url:
    username:
    password:
    driver:
    batchWorkerUiPort: 30402
    jvmOpts:
    resources:
      master:
        memory:
      taskmanger:
        memory:
        cpuCores:
        number:
  resources:
    limits: {}
    requests: {}

server:
  replicas: 3
  mode: single
  nodeAffinity:
    key: linkoopdb/dbserver
    value: true
  ports:
    jdbcPort: 9105
    regPort: 17771
    atomixPort: 5001
    syncPort: 33041
  config:
    storageBase: ldb:///tmp/linkoopdb
    batchWorkerJars: hdfs:///user/ldb/spark
    sqlLogEnabled: false
    sqlHistoryEnabled: false
    batchWorkerUiPort: 30401
    jvmOpts:
    hiveMetastoreUris:
    enableHiveSupport:
    keytab:
  resources:
    limits: {}
    requests: {}

batchWorker:
  launcher: k8s
  resources:
    cluster:
      queue:
      totalMemory:
      totalCpuCores:
      numNodes:
      numExecutorsPerHost:
      totalGpuCores:
    master:
      memory:
    taskmanger:
      memory:
      cpuCores:
      number:
      gpuCores:
  config:
    jvmOpts:

stream:
  create: true
  nodeAffinity:
    key: kubernetes.io/hostname
    values: node61,node62,node63
  config:
    yarn.properties-file.location: file:///opt/flink-yarn/session
  streamWorker:
    kafkaLibPath:
    libPath:
    ports:
      workerPort: 7778
    resources:
      limits: {}
      requests: {}
  debugWorker:
    ports:
      workerPort:
    resources:
      limits: {}
      requests: {}
  jobmanager:
    ports:
      ui: 30101
    resources:
      limits: {}
      requests: {}
  taskmanager:
    replicas: 1
    resources:
      limits: {}
      requests: {}

monitor:
  create: false

studio:
  create: false
